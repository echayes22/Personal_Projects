# -*- coding: utf-8 -*-
"""Assingment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14QC8KWw6QRr4faqns74_xIjX9FzHJDWU
"""

!wget https://raw.githubusercontent.com/tasdikrahman/datasets/master/email/csv/spam-apache.csv

#------imports utilized --------
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

csv = pd.read_csv('spam-apache.csv', header = None)
labels = csv[0].to_numpy()

emails = csv[1]
print(emails[11])    #email controls & display of outcome of what email is being viewed ; simply change integer in emails array

emails = np.array(csv[1])
import re
#extract the words that are interesting 

all_words = {}    #initialize an empty dictionary to work from

for (email_index, email) in enumerate(emails):      # gather only words and similar output from emails
  words = re.findall('[a-zA-Z]+', email.lower())    # remove punctuation, only words w/ lowercase to avoid confusion and clarity 
  
  for word in words:

    if not word in all_words.keys():
      all_words[word] = [0,0]
    all_words[word][int ((labels[email_index] + 1) /2) ] += 1
  
# for word in words in all_words:         # was meant to lowercase the words contained in dictionary, help ease word filtering/choice
#   word.lower()                          # moved to inside dictionary filler ^ (above)

all_words

#Calculates proabability of each word being determined as spam(left/bad) vs being determined as ham(right/good) in ratio
import copy
probs = copy.deepcopy(all_words)    #creation of a replica of dictionary to calc. prob. for each word in dictionary(generation of ratios)
for key in probs:
  
  s = probs[key][0] + probs[key][1]   #should be able to add up to 1, general proabability sense

  probs[key][0] /= s
  if(abs(probs[key][0] - 0.0) < 0.0000000001):     #
    probs[key][0] = 0.0000000001                   #
                                                   #Takes care of scenario when proabability of one half of the ratio is 0,
  probs[key][1] /= s                               #which should never actually be 0 itself, but a miniature number close to zero (approximation)
  if(abs(probs[key][1] - 0.0) < 0.0000000001):     #
    probs[key][0] = 0.0000000001                   #

probs

def train(train_set_size):
  all_words = {}    #initialize an empty dictionary to work from

  for (email_index, email) in enumerate(emails):    # gather only words and similar output from emails
    words = re.findall('[a-zA-Z]+', email)          #remove punctuation, only words
  
  for word in words:
    if not word in all_words.keys():
      all_words[word] = [0,0]
    all_words[word][int ((labels[email_index] + 1) /2) ] += 1

  probs = copy.deepcopy(all_words)    #creation of a replica of dictionary to calc. prob. for each word in dictionary(generation of ratios)
  for key in probs:
  
     s = probs[key][0] + probs[key][1]   #should be able to add up to 1, general proabability sense

  probs[key][0] /= s
  if(abs(probs[key][0] - 0.0) < 0.0000000001):     #
    probs[key][0] = 0.0000000001                   #
                                                   #Takes care of scenario when proabability of one half of the ratio is 0,
  probs[key][1] /= s                               #which should never actually be 0 itself, but a miniature number close to zero (approximation)
  if(abs(probs[key][1] - 0.0) < 0.0000000001):     #
    probs[key][0] = 0.0000000001  

  return probs, words

csv
#seperate the emails by category -1 / 1 
spam = csv[csv[0]== -1][1].to_numpy()
ham = csv[csv[0]== 1][1].to_numpy()

#spam[7]   view spam emails

indices = np.random.permutation(250)  #vector ; each number an index, order randomized

fraction = 0.6
fraction_point = int(fraction * np.size(labels))

train_labels = labels[indices[:fraction_point]]
train_emails = emails[indices[:fraction_point]]

test_labels = labels[indices[fraction_point:]]
test_emails = emails[indices[fraction_point:]]

# print(len(train_labels) + len(test_labels))   # total of emails

def pr_email(email, bias, probs):
  s = bias

#learning
for train_set_size in [50]:
  p_spam = np.sum((labels[:train_set_size] == 1)* 1) / train_set_size
  p_ham = 1 - p_spam
  bias = np.log(p_spam / p_ham)

  predictions = []
  probs, words = train(train_set_size)
  for (email_index, email) in enumerate(emails[train_set_size:]):
    sp_or_h = pr_email(email, bias, probs)
    predictions.append(sp_or_h)
  
  differ = predictions - label[train_set_size:]
  correct_classify = sum((differ == 0)* 1)
  correct_per = correct_classify / len(predictions)
  print(correct_per)

#evaluate algorithm on test set(disjoint training)
#algo complete, call, where email will be selected in order form test_emails
#will provide ratio/classify
pred_labels = np.sign(np.random.randn(len(test_labels)))         #turns
pred_labels

#evaluation // confusion matrix 
#0 = correct
errors = pred_labels - test_labels
errors

#true positives
true_pr = np.sum(errors == 0) / len(errors)
true_pr

#false postives // should be low
np.sum(errors == -2) / len(errors)